---
title: SQL
date: 2025-03-08 09:27:40
permalink: /pages/ce7a7d/
categories:
  - InterviewQ
tags:
  - 
---
SQL

# 为什么update一定要用索引

因为使用索引进行update时只会对这个索引项加锁。

使用没有索引的条件update时，不知道对哪一个索引加锁，导致对主键索引的每一结点进行加锁，行锁退化成了表锁

# count(1)和count(*)和count(字段)的执行速度区别



# 索引的类型有什么



# MySQL的锁有什么

全局锁：用于数据库备份

# MySQL数据库的备份

数据库备份需要对数据库加全局锁

`flush tables with read lock`

1. mysqldump（MySQL自带的工具）

   适用于小数据库

   `mysqldump -u username -p database_name table1 table2 > tables_backup.sql#备份多个表``

   ``mysqldump -u username -p database_name < tables_backup.sql#恢复备份`

2. 二进制日志文件进行增量备份

   可以配合mysqldump使用

3. 对于大型数据库使用xtrabackup



# MySQL导入大数据量

1. 如果数据使用的是文本文件(如，CSV、TSV)存储，可以使用load data [infile]
2. 如果使用的是sql文件，可以先使用一些脚本或工具将多个insert语句合并为一条，将数据分批次插入，一次不超过一千个数据（buffer pool限制），从而减少客户端与数据库的通信次数
3. 在插入时可以暂时关闭索引和外键检查，插入完毕后再开启并，如果必要，重建索引。
4. 为了保证执行过程对异常处理，可以创建一张临时的任务表，包含任务id，数据范围，任务状态等字段，每次插入数据前记录任务信息。如果插入出现异常就可以进行回滚或重试



# 导入100万数据导致数据库死锁

是因为插入的数据违反了唯一性约束

当插入的数据违反了唯一性，会导致排他锁退化为共享锁，因为要保证其他线程能访问到数据，如果有两个线程都进行插入违反唯一性，都会持有共享锁，并等待意向排他锁，因为意向排他锁和共享锁是冲突的，导致死锁



# bin log与undo log的区别



# 深分页慢，怎么优化/limit 500000 10和limit 10的比较

深分页慢是因为需要先扫描并跳过前 500,000 条记录，然后再返回接下来的 10 条数据，而limit10只需要直接返回前10条数据

优化方法

- 如果查询涉及到索引，
  - 如果是没有查询条件的，可以使用延迟关联，通过索引获取对应的10条数据的主键后，通过主键关联回表查询数据，
  - 如果是有查询条件的，可以先通过覆盖索引筛选符合条件的第50000条数据后的10条数据，如果还需要其他字段，再通过子查询查找，这样可以避免查询语句回表查询到其他字段后，再进行分页，提高性能

- 基于游标的分页：对于有序数据，可以记住上一次查询的最后一个记录的主键值，然后在下一次查询时直接从该位置开始查找。不过这种方法不能跨页查询，且主键必须是有序的

- 可以通过分库分表，将表水平拆分，这样查询只需要查询相关的表就行，但是需要解决分布式事务、全局唯一ID、跨库查询等问题
- 引入搜索引擎可以提供更强大的搜索和分页能力，特别是在处理复杂查询和大数据量时。不过这会增加系统架构的复杂度，

- 可以从业务层优化，一般不会跨过500000条数据来查询10条，所以可以通过设置查询的最大页数来限制深分页，比如淘宝、京东商品最多翻到100页



# MySQL线上修改大表结构有哪些风险

在线修改大表的表结构执行时间

可以使用工具online-schema-change，可以在不影响表的正常读写的情况下执行DDL操作



# MySQL不建议使用NULL作为默认值

SQL语言采用的是三值逻辑，除了真和假，还有第三个值`UNKNOWN`（不确定）。

- **查询复杂性增加**：
  - 使用NULL会增加查询的复杂性，因为NULL不能通过常规的比较运算符（如`=`、`<`、`>`）进行比较，必须使用`IS NULL`或`IS NOT NULL`来判断。否则，`NULL`参与逻辑运算时会返回`UNKNOWN`，导致查询结果与预期不一致。

- **索引稀疏性问题**：
  - 虽然MySQL的B+树索引可以包含NULL值，但在某些情况下（如唯一索引），NULL值可能会导致意外的行为。此外，查询优化器可能无法充分利用包含NULL值的索引，导致查询性能下降。

- **违反业务逻辑和约束**：
  - NULL值可能违反业务逻辑和数据库约束。例如，如果某个列在业务逻辑上不能为空，但允许NULL值，可能会导致数据不一致。

- **聚合函数的影响**：
  - NULL值会影响聚合函数的结果。例如，`COUNT(column)`会忽略NULL值，只计算非NULL值，这可能导致统计结果与预期不符。

- **存储和性能开销**：
  - 虽然NULL值本身不占用存储空间，但MySQL需要额外的位来标记哪些值是NULL，这会增加一些存储和性能开销。

- **替代方案**：
  - 为了避免使用NULL，可以为列设置一个有意义的默认值（如空字符串`''`、`0`或特定占位符），或者使用`NOT NULL`约束，以确保数据的完整性和一致性。



# 为什么mysql推荐使用自增id

- 自增 ID 是连续递增的整数，在插入新记录时，MySQL 可以直接将新记录追加到表的末尾（B+树的叶子节点），不会为计算新行的位置而做出额外的消耗，也不需要重新排序或调整索引结构。只有当达到页面的最大填充因子时(innodb默认的最大填充因子是页大小的15/16,会留出1/16的空间留作以后的  修改)：将下一条记录写入新的页中，一旦数据按照这种顺序的方式加载，主键页就会近乎于顺序的记录填满，提升了页面的最大填充率，不会有页的浪费，减少了页分裂和碎片的产生

- 因为uuid相对顺序的自增id来说是毫无规律可言的，每次插入都需要为新行寻找新的合适的位置，导致 B+ 树需要重新平衡，影响插入性能。

而插入数据的毫无顺序会导致数据分布散乱，将会导致以下的问题：

- 写入的目标页很可能已经刷新到磁盘上并且从缓存上移除，或者还没有被加载到缓存中，innodb在插入之前不得不先找到并从磁盘读取目标页到内存中，这将导致大量的随机IO

- 因为写入是乱序的,innodb不得不频繁的做页分裂操作,以便为新的行分配空间,页分裂导致移动大量的数据，一次插入最少需要修改三个页以上

- 由于频繁的页分裂，页会变得稀疏并被不规则的填充，最终会导致数据会有碎片


结论：使用innodb应该尽可能的按主键的自增顺序插入，

- 尽管自增ID有诸多优点，但在某些场景下可能存在局限性：

1. 可预测性：
   - 自增ID是连续的，容易被猜测，可能存在安全风险（如数据爬取或恶意攻击）。
   - 可以通过一些技术手段（如ID加密、哈希等）来增强安全性。
2. 分布式系统的挑战：
   - 在分布式系统中，自增ID需要额外的逻辑来保证全局唯一性（如使用Snowflake算法或数据库分段自增）。
3. 对于高并发的负载，innodb在按主键进行插入的时候会造成明显的锁争用，主键的上界会成为争抢的热点，因为所有的插入都发生在这里，并发插入会导致间隙锁竞争



# 数据量达到多少的时候要开始分库分表？

何时进行分库分表的依据

- 数据存储方式
- 检索方式

InnoDB使用B+树索引结构，其性能与树高度直接相关，每次树高增加意味着多一次磁盘I/O

innoDB的索引树建议控制在三层，超过三层就要考虑分库分表，

而三层可以存储多少条数据呢
- innoDB的数据是存储在页中的，一个页是16KB
- 假设非叶子结点存储的目录项（索引键值（8字节的BIGINT）+ 子页指针（6字节））为14byte，行数据为1KB，
- 第一层的非叶子结点就可以存储16KB/14B = 1170个指向第二层子节点的目录项。
- 所以第二层有1170个非叶子结点，且每个节点也可以存储1170个目录项，
- 第三层就可以有1170*1170个结点，每个结点可以存储16KB/1KB = 16 条行数据。
- 所以第三层可以存储总共1170* 1170* 16 = 2000多万条行数据

实际容量应考虑行格式、碎片率等因素，建议按理论值的70%作为预警线

高频访问的表应适当降低阈值（如按50%计算）
